{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom_lstm\n",
    "\n",
    "Custom LSTM Implementation, since Pytorch's implementations don't support Layer Normalization or Recurrent Dropout with Memory Loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp lstm.custom_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence,\n",
    "                                pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_cuda_enabled(model):\n",
    "    return next(model.parameters()).is_cuda\n",
    "\n",
    "\n",
    "def get_module_device(model):\n",
    "    return next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_indicator(length_tensor, max_length=None):\n",
    "    \"\"\"\n",
    "    :param length_tensor: \n",
    "    :param max_length: \n",
    "    :returns: a tensor where positions within ranges are set to 1\n",
    "    \"\"\"\n",
    "    if isinstance(length_tensor, (list, tuple)):\n",
    "        length_tensor = torch.tensor(length_tensor, dtype=torch.int64)\n",
    "\n",
    "    lengths_size = length_tensor.size()\n",
    "    flat_lengths = length_tensor.view(-1, 1)\n",
    "\n",
    "    if not max_length:\n",
    "        max_length = length_tensor.max()\n",
    "    unit_range = torch.arange(max_length)\n",
    "    # flat_range = torch.stack([unit_range] * flat_lengths.size()[0],\n",
    "    #                          dim=0)\n",
    "    # flat_range = unit_range.repeat(flat_lengths.size()[0], 1)\n",
    "    flat_range = unit_range.expand(flat_lengths.size()[0:1] + unit_range.size())\n",
    "    flat_indicator = flat_range < flat_lengths\n",
    "\n",
    "    return flat_indicator.view(lengths_size + (-1, 1))\n",
    "\n",
    "\n",
    "def create_lstm_cell_init_state(hidden_size, init_state_learned=True, device=None):\n",
    "    \"\"\"\n",
    "    :param hidden_size: \n",
    "    :param init_state_learned: \n",
    "    :returns: init_state is a input of lstm cells. _init_state is saved as a parameter of model (such as self._init_state)\n",
    "    \"\"\"\n",
    "    init_hidden = nn.Parameter(torch.zeros(1, hidden_size, device=device), init_state_learned)\n",
    "    init_cell = nn.Parameter(torch.zeros(1, hidden_size, device=device), init_state_learned)\n",
    "\n",
    "    init_state = (init_hidden, init_cell)\n",
    "    _init_state = nn.ParameterList(init_state)\n",
    "\n",
    "    return init_state, _init_state\n",
    "\n",
    "\n",
    "def repeat_lstm_cell_state(state, batch_size):\n",
    "    for s in state:\n",
    "        size = s.size()\n",
    "        assert len(size) == 2\n",
    "    # s is either hidden or cell\n",
    "    return tuple(\n",
    "        # s.repeat(batch_size, 1)\n",
    "        s.squeeze(0).expand((batch_size,) + s.size()[1:])\n",
    "        for s in state)\n",
    "\n",
    "\n",
    "def create_lstm_init_state(num_layers, num_directions, hidden_size, init_state_learned=True, device=None):\n",
    "    \"\"\"\n",
    "    :param hidden_size: \n",
    "    :param init_state_learned: \n",
    "    :returns: init_state is a input of lstm cells. _init_state is saved as a parameter of model (such as self._init_state)\n",
    "    \"\"\"\n",
    "    init_hidden = nn.Parameter(torch.zeros(\n",
    "        num_layers * num_directions, 1, hidden_size, device=device), init_state_learned)\n",
    "    init_cell = nn.Parameter(torch.zeros(num_layers * num_directions,\n",
    "                                         1, hidden_size, device=device), init_state_learned)\n",
    "\n",
    "    init_state = (init_hidden, init_cell)\n",
    "    _init_state = nn.ParameterList(init_state)\n",
    "\n",
    "    return init_state, _init_state\n",
    "\n",
    "\n",
    "def repeat_lstm_state(state, batch_size):\n",
    "    # s is either hidden or cell\n",
    "    return tuple(\n",
    "        s.repeat(1, batch_size, 1)\n",
    "        for s in state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# def no_dropout(x): return x\n",
    "no_dropout = nn.Identity()\n",
    "no_dropout.p = 0\n",
    "\n",
    "# def no_layer_norm(x): return x\n",
    "no_layer_norm = nn.Identity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RNNFrame(nn.Module):\n",
    "    def __init__(self, rnn_cells, for_lstm=False, batch_first=False, dropout=0, bidirectional=False):\n",
    "        \"\"\"\n",
    "        :param rnn_cells: ex) [(cell_0_f, cell_0_b), (cell_1_f, cell_1_b), ..]\n",
    "        :param dropout:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            assert all(len(pair) == 2 for pair in rnn_cells)\n",
    "        elif not any(isinstance(rnn_cells[0], iterable)\n",
    "                     for iterable in [list, tuple, nn.ModuleList]):\n",
    "            rnn_cells = tuple((cell,) for cell in rnn_cells)\n",
    "\n",
    "        self.rnn_cells = nn.ModuleList(nn.ModuleList(pair)\n",
    "                                       for pair in rnn_cells)\n",
    "        self.for_lstm = for_lstm\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = len(rnn_cells)\n",
    "\n",
    "        if dropout > 0 and self.num_layers > 1:\n",
    "            # dropout is applied to output of each layer except the last layer\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = no_dropout\n",
    "\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def get_zero_init_state(self, hidden_size):\n",
    "        # init_state with heterogenous hidden_size\n",
    "        if self.for_lstm:\n",
    "            #print(f\"get_zero_init_state - hidden_size={hidden_size}\")\n",
    "            init_hidden = init_cell = [\n",
    "                torch.zeros((hidden_size, self.rnn_cells[layer_idx][direction].hidden_size),\n",
    "                            device=get_module_device(self))\n",
    "                for layer_idx in range(self.num_layers)\n",
    "                for direction in range(self.num_directions)]\n",
    "            init_state = torch.stack(init_hidden), torch.stack(init_cell)\n",
    "        else:\n",
    "            init_state = [\n",
    "                torch.zeros((hidden_size, vself.rnn_cells[layer_idx][direction].hidden_size),\n",
    "                            device=get_module_device(self))\n",
    "                for layer_idx in range(self.num_layers)\n",
    "                for direction in range(self.num_directions)]\n",
    "        return init_state\n",
    "\n",
    "    def get_init_step_state(self, init_state, state_idx):\n",
    "        if self.for_lstm:\n",
    "            init_hidden, init_cell = init_state\n",
    "            #print(f\"RNNFrame.get_init_step_state - num_directions={self.num_directions})\")\n",
    "            #print(f\"RNNFrame.get_init_step_state - state_idx={state_idx})\")\n",
    "            #print(f\"RNNFrame.get_init_step_state = init_hidden.shape={init_hidden.shape}\")\n",
    "            #print(f\"RNNFrame.get_init_step_state = init_cell.shape={init_cell.shape}\")\n",
    "            if self.num_directions == 2:\n",
    "                return (torch.chunk(init_hidden, 2, dim=0)[state_idx].squeeze(0), torch.chunk(init_cell, 2, dim=0)[state_idx].squeeze(0))\n",
    "            else:\n",
    "                return (init_hidden, init_cell)\n",
    "            #step_state = (init_hidden[state_idx], init_cell[state_idx])\n",
    "        else:\n",
    "            step_state = init_state[state_idx]\n",
    "        return step_state\n",
    "\n",
    "    def get_step_output(self, step_state):\n",
    "        if self.for_lstm:\n",
    "            h, c = step_state\n",
    "            step_output = h\n",
    "        else:\n",
    "            step_output = step_state\n",
    "            \n",
    "        return step_output\n",
    "\n",
    "    def get_direction_last_state(self, step_state_list, lengths):\n",
    "        if self.for_lstm:\n",
    "            direction_last_state = tuple(\n",
    "                torch.stack([h_or_c[length - 1][example_id]\n",
    "                             for example_id, length in enumerate(lengths)], dim=0)\n",
    "                for h_or_c in zip(*step_state_list))\n",
    "            # direction_last_hidden, direction_last_cell = direction_last_state\n",
    "        else:\n",
    "            direction_last_state = \\\n",
    "                torch.stack([step_state_list[length - 1][example_id]\n",
    "                             for example_id, length in enumerate(lengths)], dim=0)\n",
    "        return direction_last_state\n",
    "\n",
    "    def get_last_state(self, direction_last_state_list):\n",
    "        if self.for_lstm:\n",
    "            last_state = tuple(\n",
    "                torch.stack(direction_last_h_or_c_list, dim=0)\n",
    "                for direction_last_h_or_c_list in zip(*direction_last_state_list))\n",
    "            # h_n, c_n = last_state\n",
    "        else:\n",
    "            last_state = torch.stack(direction_last_state_list, dim=0)\n",
    "        return last_state\n",
    "\n",
    "    def align_sequence(self, seq, lengths, shift_right):\n",
    "        \"\"\"\n",
    "        :param seq: (seq_len, batch_size, *)\n",
    "        \"\"\"\n",
    "        multiplier = 1 if shift_right else -1\n",
    "        example_seqs = torch.split(seq, 1, dim=1)\n",
    "        max_length = max(lengths)\n",
    "        shifted_seqs = [example_seq.roll((max_length - length) * multiplier, dims=0)\n",
    "                        for example_seq, length in zip(example_seqs, lengths)]\n",
    "        return torch.cat(shifted_seqs, dim=1)\n",
    "\n",
    "    def forward(self, input, state=None):\n",
    "        \"\"\"\n",
    "        :param input: a tensor(s) of shape (seq_len, batch, input_size)\n",
    "        :param state: (h_0, c_0) where the size of both is (num_layers * num_directions, batch, hidden_size)\n",
    "        :returns: (output, (h_n, c_n))\n",
    "        - output: (seq_len, batch, num_directions * hidden_size)\n",
    "        - h_n: (num_layers * num_directions, batch, hidden_size)\n",
    "        - c_n: (num_layers * num_directions, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        # #print(f\"RNNFrame.forward - state.shape[0]={state[0].shape}\")\n",
    "\n",
    "        if isinstance(input, torch.nn.utils.rnn.PackedSequence):\n",
    "            input_packed = True\n",
    "            # always batch_first=False --> trick to process input regardless of batch_first option\n",
    "            input, lengths = pad_packed_sequence(input, batch_first=False)\n",
    "            if max(lengths) == min(lengths):\n",
    "                uniform_length = True\n",
    "            else:\n",
    "                uniform_length = False\n",
    "            if isinstance(lengths, torch.Tensor):\n",
    "                lengths = tuple(lengths.detach().cpu().numpy())\n",
    "            assert max(lengths) == input.size()[0]\n",
    "        else:\n",
    "            input_packed = False\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1)\n",
    "            lengths = [input.size()[0]] * input.size()[1]\n",
    "            uniform_length = True\n",
    "\n",
    "        if not uniform_length:\n",
    "            indicator = get_indicator(torch.tensor(lengths, device=get_module_device(self)))\n",
    "\n",
    "        if state is None:\n",
    "            #print(f\"input.size()[1] = {input.size()[1]}\")\n",
    "            state = self.get_zero_init_state(input.size()[1])\n",
    "        hx, cx = state\n",
    "        # hx = torch.stack(state[0])\n",
    "        # cx = torch.stack(state[1])\n",
    "        # #print(f\"hx.shape = {len(hx)}\")\n",
    "        #print(hx)\n",
    "        #print(f\"RNNFramge.forward - state[0].shape={hx.shape}\")\n",
    "        #print(f\"RNNFramge.forward - state[1].shape={cx.shape}\")\n",
    "\n",
    "        direction_last_state_list = []\n",
    "        layer_output = input\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            layer_input = layer_output\n",
    "            if layer_idx != 0:\n",
    "                layer_input = self.dropout(layer_input)\n",
    "\n",
    "            direction_output_list = []\n",
    "\n",
    "            for direction in range(self.num_directions):\n",
    "                cell = self.rnn_cells[layer_idx][direction]\n",
    "                state_idx = layer_idx * self.num_directions + direction\n",
    "                step_state = self.get_init_step_state(state, state_idx)\n",
    "                # #print(step_state)\n",
    "                # #print(step_state[0])\n",
    "                # #print(step_state[0][0])\n",
    "                #print(f\"RNNFramge.forward - step_state[0].shape={step_state[0].shape}\")\n",
    "                #print(f\"RNNFramge.forward - step_state[1].shape={step_state[1].shape}\")\n",
    "\n",
    "                direction_output = torch.zeros(\n",
    "                    layer_input.size()[:2] + (cell.hidden_size,),\n",
    "                    device=get_module_device(self))  # (seq_len, batch_size, hidden_size)\n",
    "                step_state_list = []\n",
    "\n",
    "                if direction == 0:\n",
    "                    step_input_gen = enumerate(layer_input)\n",
    "                else:\n",
    "                    step_input_gen = reversed(list(enumerate(\n",
    "                        layer_input if uniform_length else\n",
    "                        self.align_sequence(layer_input, lengths, True))))\n",
    "\n",
    "                for seq_idx, cell_input in step_input_gen:\n",
    "                    step_state = cell(cell_input, step_state)\n",
    "                    direction_output[seq_idx] = self.get_step_output(step_state)\n",
    "                    step_state_list.append(step_state)\n",
    "                if direction == 1 and not uniform_length:\n",
    "                    direction_output = self.align_sequence(\n",
    "                        direction_output, lengths, False)\n",
    "\n",
    "                if uniform_length:\n",
    "                    # hidden & cell's size = (batch, hidden_size)\n",
    "                    direction_last_state = step_state_list[-1]\n",
    "                else:\n",
    "                    direction_last_state = self.get_direction_last_state(step_state_list, lengths)\n",
    "\n",
    "                direction_output_list.append(direction_output)\n",
    "                direction_last_state_list.append(direction_last_state)\n",
    "\n",
    "            if self.num_directions == 2:\n",
    "                assert direction_output_list[0].size() == direction_output_list[1].size()\n",
    "                layer_output = torch.stack(direction_output_list, dim=2).view(\n",
    "                    direction_output_list[0].size()[:2] + (-1,))\n",
    "            else:\n",
    "                layer_output = direction_output_list[0]\n",
    "\n",
    "        output = layer_output\n",
    "        last_state = self.get_last_state(direction_last_state_list)\n",
    "\n",
    "        if not uniform_length:\n",
    "            # the below one line code cleans out trash values beyond the range of lengths.\n",
    "            # actually, the code is for debugging, so it can be removed to enhance computing speed slightly.\n",
    "            output = (\n",
    "                output.transpose(0, 1) * indicator).transpose(0, 1)\n",
    "\n",
    "        if input_packed:\n",
    "            output = pack_padded_sequence(output, lengths, batch_first=self.batch_first)\n",
    "        elif self.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "\n",
    "        return output, last_state\n",
    "\n",
    "\n",
    "class LSTMFrame(RNNFrame):\n",
    "    \"Wrapper of RNNFrame. The 'for_lstm' option is always 'True'.\"\n",
    "\n",
    "    def __init__(self, rnn_cells, batch_first=False, dropout=0, bidirectional=False):\n",
    "        super().__init__(rnn_cells,\n",
    "                         for_lstm=True,\n",
    "                         batch_first=batch_first,\n",
    "                         dropout=dropout,\n",
    "                         bidirectional=bidirectional)\n",
    "\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    standard LSTM cell\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fiou_linear = nn.Linear(input_size + hidden_size, hidden_size * 4)\n",
    "        # self.reset_parameters()\n",
    "\n",
    "    # def reset_parameters(self):\n",
    "    #     stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    #     for weight in self.parameters():\n",
    "    #         weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        \"\"\"\n",
    "        :param input: a tensor of of shape (batch_size, input_size)\n",
    "        :param state: a pair of a hidden tensor and a cell tensor whose shape is (batch_size, hidden_size).\n",
    "                      ex. (h_0, c_0)\n",
    "        :returns: 1-dimensional hidden and cell\n",
    "        \"\"\"\n",
    "        hidden_tensor, cell_tensor = state\n",
    "\n",
    "        # print(f\"LSTMCell.forward: input={input.shape}, hidden_tensor={hidden_tensor.shape}\")\n",
    "\n",
    "        assert len(input.shape) == 2\n",
    "        if len(hidden_tensor.shape) == 3:\n",
    "            hidden_tensor = hidden_tensor.squeeze(0)\n",
    "        if len(cell_tensor.shape) == 3:\n",
    "            cell_tensor = cell_tensor.squeeze(0)\n",
    "\n",
    "        # print(f\"LSTMCell.forward: input={input.shape}, hidden_tensor={hidden_tensor.shape}\")\n",
    "        fio_linear, u_linear = torch.split(\n",
    "            self.fiou_linear(torch.cat([input, hidden_tensor], dim=1)),\n",
    "            self.hidden_size * 3, dim=1)\n",
    "\n",
    "        f, i, o = torch.split(torch.sigmoid(fio_linear),\n",
    "                              self.hidden_size, dim=1)\n",
    "        u = torch.tanh(u_linear)\n",
    "\n",
    "        new_cell = i * u + (f * cell_tensor)\n",
    "        new_h = o * torch.tanh(new_cell)\n",
    "\n",
    "        return new_h, new_cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LayerNormRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, layer_norm_enabled=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(\n",
    "            input_size + hidden_size, hidden_size, bias=not layer_norm_enabled)\n",
    "\n",
    "        # if dropout is not None:\n",
    "        #     if isinstance(dropout, nn.Dropout):\n",
    "        #         self.dropout = dropout\n",
    "        #     elif dropout > 0:\n",
    "        #         self.dropout = nn.Dropout(dropout)\n",
    "        #     else:\n",
    "        #         self.dropout = no_dropout\n",
    "\n",
    "        self.layer_norm_enabled = layer_norm_enabled\n",
    "        if layer_norm_enabled:\n",
    "            self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        else:\n",
    "            self.layer_norm = no_layer_norm\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\n",
    "        :param input: a tensor of of shape (batch_size, input_size)\n",
    "        :param state: a hidden tensor of shape (batch_size, hidden_size).\n",
    "                      ex. (h_0, c_0)\n",
    "        :returns: hidden and cell\n",
    "        \"\"\"\n",
    "        return torch.tanh(self.layer_norm(self.linear(\n",
    "            torch.cat([input, hidden], dim=1))))\n",
    "\n",
    "\n",
    "class LayerNormLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    It's based on tf.contrib.rnn.LayerNormBasicLSTMCell\n",
    "    Reference:\n",
    "    - https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LayerNormBasicLSTMCell\n",
    "    - https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1335\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, dropout=None, layer_norm_enabled=True, cell_ln=None):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fiou_linear = nn.Linear(\n",
    "            input_size + hidden_size, hidden_size * 4, bias=not layer_norm_enabled)\n",
    "\n",
    "        if dropout is not None:\n",
    "            # recurrent dropout is applied\n",
    "            if isinstance(dropout, nn.Dropout):\n",
    "                self.dropout = dropout\n",
    "            elif dropout > 0:\n",
    "                self.dropout = nn.Dropout(dropout)\n",
    "            else:\n",
    "                assert dropout >= 0\n",
    "                self.dropout = no_dropout\n",
    "        else:\n",
    "            self.dropout = no_dropout\n",
    "\n",
    "        self.layer_norm_enabled = layer_norm_enabled\n",
    "        if layer_norm_enabled:\n",
    "            self.fiou_ln_layers = nn.ModuleList(\n",
    "                nn.LayerNorm(hidden_size) for _ in range(4))\n",
    "            # self.fiou_ln_layers = nn.ModuleList(\n",
    "            #     nn.LayerNorm(hidden_size) for _ in range(3))\n",
    "            # self.fiou_ln_layers.append(\n",
    "            #     nn.LayerNorm(hidden_size) if u_ln is None else u_ln)\n",
    "            self.cell_ln = nn.LayerNorm(\n",
    "                hidden_size) if cell_ln is None else cell_ln\n",
    "        else:\n",
    "            assert cell_ln is None\n",
    "            # assert u_ln is cell_ln is None\n",
    "            self.fiou_ln_layers = (no_layer_norm,) * 4\n",
    "            self.cell_ln = no_layer_norm\n",
    "        # self.reset_parameters()\n",
    "\n",
    "    # def reset_parameters(self):\n",
    "    #     stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    #     for weight in self.parameters():\n",
    "    #         weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        \"\"\"\n",
    "        :param input: a tensor of of shape (batch_size, input_size)\n",
    "        :param state: a pair of a hidden tensor and a cell tensor whose shape is (batch_size, hidden_size).\n",
    "                      ex. (h_0, c_0)\n",
    "        :returns: hidden and cell\n",
    "        \"\"\"\n",
    "        hidden_tensor, cell_tensor = state\n",
    "        \n",
    "        assert len(input.shape) == 2\n",
    "        if len(hidden_tensor.shape) == 3:\n",
    "            hidden_tensor = hidden_tensor.squeeze(0)\n",
    "        if len(cell_tensor.shape) == 3:\n",
    "            cell_tensor = cell_tensor.squeeze(0)\n",
    "\n",
    "        fiou_linear = self.fiou_linear(\n",
    "            torch.cat([input, hidden_tensor], dim=1))\n",
    "        fiou_linear_tensors = fiou_linear.split(self.hidden_size, dim=1)\n",
    "\n",
    "        # if self.layer_norm_enabled:\n",
    "        fiou_linear_tensors = tuple(ln(tensor) for ln, tensor in zip(\n",
    "            self.fiou_ln_layers, fiou_linear_tensors))\n",
    "\n",
    "        f, i, o = tuple(torch.sigmoid(tensor)\n",
    "                        for tensor in fiou_linear_tensors[:3])\n",
    "        u = self.dropout(torch.tanh(fiou_linear_tensors[3]))\n",
    "\n",
    "        new_cell = self.cell_ln(i * u + (f * cell_tensor))\n",
    "        new_h = o * torch.tanh(new_cell)\n",
    "\n",
    "        return new_h, new_cell\n",
    "\n",
    "\n",
    "class LayerNormLSTM(LSTMFrame):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, batch_first=False, dropout=0, r_dropout=0, bidirectional=False, layer_norm_enabled=True):\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.r_dropout = r_dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.layer_norm_enabled = layer_norm_enabled\n",
    "\n",
    "        r_dropout_layer = nn.Dropout(r_dropout)\n",
    "        rnn_cells = tuple(\n",
    "            tuple(\n",
    "                LayerNormLSTMCell(\n",
    "                    input_size if layer_idx == 0 else hidden_size * (2 if bidirectional else 1),\n",
    "                    hidden_size,\n",
    "                    dropout=r_dropout_layer,\n",
    "                    layer_norm_enabled=layer_norm_enabled)\n",
    "                for _ in range(2 if bidirectional else 1))\n",
    "            for layer_idx in range(num_layers))\n",
    "\n",
    "        super().__init__(rnn_cells=rnn_cells, dropout=dropout,\n",
    "                         batch_first=batch_first, bidirectional=bidirectional)\n",
    "\n",
    "\n",
    "def forward_rnn(rnn, init_state, input, lengths, batch_first=False,\n",
    "                embedding: torch.nn.Embedding = None,\n",
    "                dropout: torch.nn.Dropout = None,\n",
    "                return_packed_output=False):\n",
    "    # \"batch_first\" means whether \"input\" is a batch-first tensor\n",
    "    padded = pad_sequence(input, batch_first=batch_first)\n",
    "    if embedding is not None:\n",
    "        padded = embedding(padded)\n",
    "    if dropout is not None:\n",
    "        padded = dropout(padded)\n",
    "    packed = pack_padded_sequence(padded, lengths, batch_first=batch_first, enforce_sorted=False)\n",
    "    packed_output, last_state = rnn(packed, init_state)\n",
    "    # (ht, ct) = last_state  # when rnn is a lstm\n",
    "    if return_packed_output:\n",
    "        return packed_output, last_state\n",
    "    else:\n",
    "        output, lengths2 = pad_packed_sequence(packed_output, batch_first=batch_first)\n",
    "        return output, last_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
