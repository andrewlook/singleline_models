{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sketch_rnn.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from singleline_models.dataset import StrokesDataset, augment_strokes, random_scale\n",
    "from singleline_models.lstm.all import LSTM_BUILTIN, LSTM_RNNLIB\n",
    "from singleline_models.sketch_rnn.model import DecoderRNN, EncoderRNN, KLDivLoss, ReconstructionLoss\n",
    "from singleline_models.sketch_rnn.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HParams():\n",
    "    architecture = 'Pytorch-SketchRNN'\n",
    "\n",
    "    dataset_source: str = 'look'\n",
    "    dataset_name: str = 'look_i16__minn10_epsilon1'\n",
    "\n",
    "    # duration of training run\n",
    "    epochs = 50000\n",
    "    # how often to compute validation metrics / persist / sample\n",
    "    save_every_n_epochs = 100\n",
    "    # validate_every_n_epochs = 2\n",
    "\n",
    "    # adaptive learning rate\n",
    "    lr = 1e-3\n",
    "    use_lr_decay = False\n",
    "    min_lr = 1e-5\n",
    "    lr_decay = 0.9999\n",
    "\n",
    "    # recurrent dropout\n",
    "    use_recurrent_dropout = False\n",
    "    r_dropout_prob = 0.1\n",
    "\n",
    "    # layer normalization\n",
    "    use_layer_norm = True\n",
    "    layer_norm_learnable = False\n",
    "\n",
    "    # data augmentation\n",
    "    augment_stroke_prob = 0.1\n",
    "    use_random_scale = True\n",
    "    random_scale_factor = 0.15\n",
    "\n",
    "    # lstm_impl = LSTM_BUILTIN\n",
    "    lstm_impl = LSTM_RNNLIB\n",
    "    \n",
    "    # Encoder and decoder sizes\n",
    "    enc_hidden_size = 256\n",
    "    dec_hidden_size = 512\n",
    "\n",
    "    # Batch size\n",
    "    batch_size = 100\n",
    "\n",
    "    # Number of features in $z$\n",
    "    d_z = 128\n",
    "    # Number of distributions in the mixture, $M$\n",
    "    n_distributions = 20\n",
    "\n",
    "    # Weight of KL divergence loss, $w_{KL}$\n",
    "    kl_div_loss_weight = 0.5\n",
    "    # decaying weight of KL loss\n",
    "    use_eta = False\n",
    "    eta_min = 1e-2\n",
    "    eta_R = 0.99995\n",
    "\n",
    "    # Gradient clipping\n",
    "    grad_clip = 1.\n",
    "    # Temperature $\\tau$ for sampling\n",
    "    temperature = 0.4\n",
    "\n",
    "    # Filter out stroke sequences longer than $200$\n",
    "    max_seq_length = 200\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {k: getattr(self, k) for k in self.__dir__() if not k.startswith('__')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Trainer():\n",
    "    # Device configurations to pick the device to run the experiment\n",
    "    device: str\n",
    "    \n",
    "    encoder: EncoderRNN\n",
    "    decoder: DecoderRNN\n",
    "    optimizer: optim.Adam\n",
    "    sampler: Sampler\n",
    "\n",
    "    train_loader: DataLoader\n",
    "    valid_loader: DataLoader\n",
    "    train_dataset: StrokesDataset\n",
    "    valid_dataset: StrokesDataset\n",
    "\n",
    "    kl_div_loss = KLDivLoss()\n",
    "    reconstruction_loss = ReconstructionLoss()\n",
    "\n",
    "    learning_rate: float\n",
    "\n",
    "    best_val_loss: float = float('inf')\n",
    "\n",
    "    def __init__(self,\n",
    "                 hp: HParams,\n",
    "                 device=\"cuda\",\n",
    "                 models_dir=\"models\",\n",
    "                 use_wandb=False,\n",
    "                 wandb_project='sketchrnn-pytorch',\n",
    "                 wandb_entity='andrewlook'):\n",
    "        self.hp = hp\n",
    "        self.device = device\n",
    "        self.use_wandb = use_wandb\n",
    "        \n",
    "        # create a unique run ID, to distinguish saved model checkpoints / sample images\n",
    "        self.run_id = f\"{math.floor(np.random.rand() * 1e6):07d}\"\n",
    "        if self.use_wandb:\n",
    "            run = wandb.init(\n",
    "                project=wandb_project,\n",
    "                entity=wandb_entity,\n",
    "                config=hp.__dict__(),\n",
    "            )\n",
    "            # use wandb's run ID, if available, so checkpoints match W&B's dashboard ID\n",
    "            self.run_id = run.id\n",
    "\n",
    "        print('='*60)\n",
    "        print(f\"RUN_ID: {self.run_id}\\n\")\n",
    "        print(f\"HYPERPARAMETERS:\\n\")\n",
    "        print(json.dumps(hp.__dict__(), indent=2))\n",
    "        print('='*60 + '\\n\\n')\n",
    "\n",
    "        self.models_dir = Path(models_dir)\n",
    "        self.run_dir = self.models_dir / self.run_id\n",
    "        if not os.path.isdir(self.run_dir):\n",
    "            os.makedirs(self.run_dir)\n",
    "\n",
    "        # Initialize step count, to be updated in the training loop\n",
    "        self.total_steps = 0\n",
    "        \n",
    "        # Initialize encoder & decoder\n",
    "        self.encoder = EncoderRNN(\n",
    "            self.hp.d_z,\n",
    "            self.hp.enc_hidden_size,\n",
    "            use_recurrent_dropout=self.hp.use_recurrent_dropout,\n",
    "            r_dropout_prob=self.hp.r_dropout_prob,\n",
    "            use_layer_norm=self.hp.use_layer_norm,\n",
    "            layer_norm_learnable=self.hp.layer_norm_learnable,\n",
    "            lstm_impl=self.hp.lstm_impl,\n",
    "        ).to(self.device)\n",
    "        self.decoder = DecoderRNN(\n",
    "            self.hp.d_z,\n",
    "            self.hp.dec_hidden_size,\n",
    "            self.hp.n_distributions,\n",
    "            use_recurrent_dropout=self.hp.use_recurrent_dropout,\n",
    "            r_dropout_prob=self.hp.r_dropout_prob,\n",
    "            use_layer_norm=self.hp.use_layer_norm,\n",
    "            layer_norm_learnable=self.hp.layer_norm_learnable,\n",
    "            lstm_impl=self.hp.lstm_impl,\n",
    "        ).to(self.device)\n",
    "\n",
    "        if self.use_wandb:\n",
    "            wandb.watch((self.encoder, self.decoder), log=\"all\", log_freq=10, log_graph=True)\n",
    "\n",
    "        # store learning rate as state, so it can be modified by LR decay\n",
    "        self.learning_rate = self.hp.lr\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), self.learning_rate)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), self.learning_rate)\n",
    "\n",
    "        self.eta_step = self.hp.eta_min if self.hp.use_eta else 1\n",
    "\n",
    "        # `npz` file path is `data/quickdraw/[DATASET NAME].npz`\n",
    "        base_path = Path(f\"data/{self.hp.dataset_source}\")\n",
    "        path = base_path / f'{self.hp.dataset_name}.npz'\n",
    "        # Load the numpy file\n",
    "        dataset = np.load(str(path), encoding='latin1', allow_pickle=True)\n",
    "\n",
    "        # Create training dataset\n",
    "        self.train_dataset = StrokesDataset(dataset['train'], self.hp.max_seq_length)\n",
    "        # Create validation dataset\n",
    "        self.valid_dataset = StrokesDataset(dataset['valid'], self.hp.max_seq_length, self.train_dataset.scale)\n",
    "\n",
    "        def collate_fn(batch, **kwargs):\n",
    "            assert type(batch) == list\n",
    "            # assert len(batch) == self.hp.batch_size\n",
    "\n",
    "            all_data = []\n",
    "            all_mask = []\n",
    "            for data, mask in batch:\n",
    "                assert data.shape[0] == self.hp.max_seq_length + 2\n",
    "                assert data.shape[1] == 5\n",
    "                assert len(data.shape) == 2\n",
    "                assert mask.shape[0] == self.hp.max_seq_length + 1\n",
    "                assert len(mask.shape) == 1\n",
    "\n",
    "                _data = data\n",
    "                if self.hp.use_random_scale:\n",
    "                    _data = random_scale(data, self.hp.random_scale_factor)\n",
    "\n",
    "                if self.hp.augment_stroke_prob > 0:\n",
    "                    _data = augment_strokes(_data, self.hp.augment_stroke_prob)\n",
    "\n",
    "                all_data.append(data)\n",
    "                all_mask.append(mask)\n",
    "\n",
    "\n",
    "            # print(f\"collate - batch: {len(batch)}, {batch[0][0].shape}, {batch[0][1].shape}\")\n",
    "            # print(f\"collate - kwargs: {kwargs}\")\n",
    "            return torch.stack(all_data), torch.stack(all_mask)\n",
    "\n",
    "        # Create training data loader\n",
    "        self.train_loader = DataLoader(self.train_dataset, self.hp.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        # Create validation data loader\n",
    "        self.valid_loader = DataLoader(self.valid_dataset, self.hp.batch_size)\n",
    "\n",
    "        # Create sampler\n",
    "        self.sampler = Sampler(self.encoder, self.decoder)\n",
    "        # Pick 5 indices from the validation dataset, so the sampling can be compared across epochs\n",
    "        self.valid_idxs = [np.random.choice(len(self.valid_dataset)) for _ in range(5)]\n",
    "\n",
    "    def save(self, epoch):\n",
    "        torch.save(self.encoder.state_dict(), \\\n",
    "            Path(self.run_dir) / f'runid-{self.run_id}_epoch-{epoch:05d}_encoderRNN.pth')\n",
    "        torch.save(self.decoder.state_dict(), \\\n",
    "            Path(self.run_dir) / f'runid-{self.run_id}_epoch-{epoch:05d}_decoderRNN.pth')\n",
    "\n",
    "    def load(self, epoch):\n",
    "        extra_args = {}\n",
    "        if self.device != 'cuda':\n",
    "            extra_args=dict(map_location=torch.device('cpu'))\n",
    "        saved_encoder = torch.load(Path(self.run_dir) / f'runid-{self.run_id}_epoch-{epoch:05d}_encoderRNN.pth', **extra_args)\n",
    "        saved_decoder = torch.load(Path(self.run_dir) / f'runid-{self.run_id}_epoch-{epoch:05d}_decoderRNN.pth', **extra_args)\n",
    "        self.encoder.load_state_dict(saved_encoder)\n",
    "        self.decoder.load_state_dict(saved_decoder)\n",
    "    \n",
    "    def log(self, metrics):\n",
    "        if self.use_wandb:\n",
    "            wandb.log(metrics, step=self.total_steps)\n",
    "        else:\n",
    "            pass\n",
    "            #pprint({'step': self.total_steps, **metrics})\n",
    "\n",
    "    def sample(self, epoch, display=False):\n",
    "        orig_paths = []\n",
    "        decoded_paths = []\n",
    "        for idx in self.valid_idxs:\n",
    "            orig_path = self.run_dir / f'runid-{self.run_id}_epoch-{epoch:05d}_sample-{idx:04d}_orig.png'\n",
    "            decoded_path = self.run_dir / f'runid-{self.run_id}_epoch-{epoch:05d}_sample-{idx:04d}_decoded.png'\n",
    "\n",
    "            # Randomly pick a sample from validation dataset to encoder\n",
    "            data, *_ = self.valid_dataset[idx]\n",
    "            self.sampler.plot(data, orig_path)\n",
    "\n",
    "            # Add batch dimension and move it to device\n",
    "            data_batched = data.unsqueeze(1).to(self.device)\n",
    "            # Sample\n",
    "            self.sampler.sample(data_batched, self.hp.temperature, decoded_path)\n",
    "\n",
    "            if display:\n",
    "                Image.open(orig_path).show()\n",
    "                Image.open(decoded_path).show()\n",
    "            orig_paths.append(orig_path)\n",
    "            decoded_paths.append(decoded_path)\n",
    "        return sorted(orig_paths), sorted(decoded_paths)   \n",
    "\n",
    "    def step(self, batch: Any, is_training=False):\n",
    "        self.encoder.train(is_training)\n",
    "        self.decoder.train(is_training)\n",
    "\n",
    "        # Move `data` and `mask` to device and swap the sequence and batch dimensions.\n",
    "        # `data` will have shape `[seq_len, batch_size, 5]` and\n",
    "        # `mask` will have shape `[seq_len, batch_size]`.\n",
    "        data = batch[0].to(self.device).transpose(0, 1)\n",
    "        mask = batch[1].to(self.device).transpose(0, 1)\n",
    "        batch_items = len(data)\n",
    "\n",
    "        # print(f\"Trainer.step - data: {data.shape}\")\n",
    "        # print(data[:5,0])\n",
    "        \n",
    "        # Get $z$, $\\mu$, and $\\hat{\\sigma}$\n",
    "        z, mu, sigma_hat = self.encoder(data)\n",
    "\n",
    "        # Concatenate $[(\\Delta x, \\Delta y, p_1, p_2, p_3); z]$\n",
    "        z_stack = z.unsqueeze(0).expand(data.shape[0] - 1, -1, -1)\n",
    "        inputs = torch.cat([data[:-1], z_stack], 2)\n",
    "        # Get mixture of distributions and $\\hat{q}$\n",
    "        dist, q_logits, _ = self.decoder(inputs, z, None)\n",
    "\n",
    "        # $L_{KL}$\n",
    "        kl_loss = self.kl_div_loss(sigma_hat, mu)\n",
    "        if self.hp.use_eta:\n",
    "            kl_loss *= self.eta_step\n",
    "\n",
    "        # $L_R$\n",
    "        reconstruction_loss = self.reconstruction_loss(mask, data[1:], dist, q_logits)\n",
    "        # $Loss = L_R + w_{KL} L_{KL}$\n",
    "        loss = reconstruction_loss + self.hp.kl_div_loss_weight * kl_loss\n",
    "\n",
    "        # Only if we are in training state\n",
    "        if is_training:\n",
    "            # Set `grad` to zero\n",
    "            self.encoder_optimizer.zero_grad()\n",
    "            self.decoder_optimizer.zero_grad()\n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            # Clip gradients\n",
    "            nn.utils.clip_grad_norm_(self.encoder.parameters(), self.hp.grad_clip)\n",
    "            nn.utils.clip_grad_norm_(self.decoder.parameters(), self.hp.grad_clip)\n",
    "            # Optimize\n",
    "            self.encoder_optimizer.step()\n",
    "            self.decoder_optimizer.step()\n",
    "        return loss.item(), reconstruction_loss.item(), kl_loss.item(), batch_items\n",
    "\n",
    "    def validate_one_epoch(self, epoch):\n",
    "        total_items, total_loss, total_kl_loss, total_reconstruction_loss = 0, 0, 0, 0\n",
    "        with torch.no_grad():    \n",
    "            for batch in iter(self.valid_loader):\n",
    "                loss, reconstruction_loss, kl_loss, batch_items = self.step(batch, is_training=False)\n",
    "\n",
    "                total_loss += loss * batch_items\n",
    "                total_reconstruction_loss += reconstruction_loss * batch_items\n",
    "                total_kl_loss += kl_loss * batch_items\n",
    "                total_items += batch_items\n",
    "                \n",
    "        avg_loss = total_loss / total_items\n",
    "        avg_reconstruction_loss = total_reconstruction_loss / total_items\n",
    "        avg_kl_loss = total_kl_loss / total_items\n",
    "        self.log(dict(\n",
    "            val_avg_loss=avg_loss,\n",
    "            val_avg_reconstruction_loss=avg_reconstruction_loss,\n",
    "            val_avg_kl_loss=avg_kl_loss,\n",
    "            epoch=epoch))\n",
    "        return avg_loss, avg_reconstruction_loss, avg_kl_loss\n",
    "\n",
    "    def train_one_epoch(self, epoch, parent_progressbar=None):\n",
    "        steps_per_epoch = len(self.train_loader)\n",
    "        for idx, batch in enumerate(progress_bar(iter(self.train_loader), parent=parent_progressbar)):\n",
    "            self.total_steps = idx + epoch * steps_per_epoch\n",
    "            loss, reconstruction_loss, kl_loss, _ = self.step(batch, is_training=True)\n",
    "            self.log(dict(\n",
    "                loss=loss,\n",
    "                reconstruction_loss=reconstruction_loss,\n",
    "                kl_loss=kl_loss,\n",
    "                epoch=epoch,\n",
    "                learning_rate=self.learning_rate,\n",
    "                eta_step=self.eta_step))\n",
    "        # update learning rate, if use_lr_decay is enabled\n",
    "        if self.hp.use_lr_decay:\n",
    "            if self.learning_rate > self.hp.min_lr:\n",
    "                self.learning_rate *= self.hp.lr_decay\n",
    "            self.encoder_optimizer = self.update_lr(self.encoder_optimizer, self.learning_rate)\n",
    "            self.decoder_optimizer = self.update_lr(self.decoder_optimizer, self.learning_rate)\n",
    "        # update weight of KL loss, if use_eta is enabled\n",
    "        if self.hp.use_eta:\n",
    "            self.eta_step = 1-(1-self.hp.eta_min)*self.hp.eta_R\n",
    "\n",
    "    def update_lr(self, optimizer, lr):\n",
    "        \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return optimizer\n",
    "        \n",
    "    def train(self):\n",
    "        mb = master_bar(range(self.hp.epochs))\n",
    "        for epoch in mb:\n",
    "            self.train_one_epoch(epoch=epoch, parent_progressbar=mb)\n",
    "            val_avg_loss, *_ = self.validate_one_epoch(epoch)\n",
    "            update_best_val = False\n",
    "            if val_avg_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_avg_loss\n",
    "                update_best_val = True\n",
    "                #if epoch % self.hp.save_every_n_epochs == 0:\n",
    "                self.save(epoch=0)\n",
    "                self.sample(epoch=0)\n",
    "            mb.write(f\"Finished epoch {epoch}. Validation Loss: {val_avg_loss}{' (new best)' if update_best_val else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
