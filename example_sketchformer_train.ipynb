{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae4a86-b115-4c5a-98eb-934c619fe15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de618f67-088b-4e42-ba00-9c352fbe367c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafeffe7-76cf-44c9-8b01-913501dbb4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using run_dir: models/0381545\n",
      "============================================================\n",
      "RUN_ID: 0381545\n",
      "\n",
      "HYPERPARAMETERS:\n",
      "\n",
      "{\n",
      "  \"n_layer\": 4,\n",
      "  \"n_head\": 8,\n",
      "  \"d_model\": 128,\n",
      "  \"d_ff\": 512,\n",
      "  \"d_lowerdim\": 256,\n",
      "  \"vocab_size\": null,\n",
      "  \"block_size\": null,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"max_seq_length\": 250,\n",
      "  \"batch_size\": 100,\n",
      "  \"blind_decoder_mask\": true,\n",
      "  \"dataset_source\": \"look\",\n",
      "  \"dataset_name\": \"look_i16__minn10_epsilon1\",\n",
      "  \"dataset_fname\": \"data/look/epoch-20231214-filtered-trainval.npz\",\n",
      "  \"augment_stroke_prob\": 0.1,\n",
      "  \"use_random_scale\": true,\n",
      "  \"random_scale_factor\": 0.15,\n",
      "  \"epochs\": 50000,\n",
      "  \"lr\": 0.001,\n",
      "  \"use_lr_decay\": true,\n",
      "  \"min_lr\": 1e-05,\n",
      "  \"lr_decay\": 0.9999,\n",
      "  \"learning_rate\": 0.001\n",
      "}\n",
      "============================================================\n",
      "\n",
      "\n",
      "truncating 16 - length: 266\n",
      "truncating 27 - length: 254\n",
      "truncating 51 - length: 257\n",
      "truncating 60 - length: 289\n",
      "truncating 88 - length: 260\n",
      "truncating 113 - length: 259\n",
      "truncating 135 - length: 276\n",
      "truncating 142 - length: 252\n",
      "truncating 150 - length: 282\n",
      "truncating 152 - length: 270\n",
      "truncating 174 - length: 298\n",
      "truncating 187 - length: 289\n",
      "truncating 237 - length: 294\n",
      "truncating 242 - length: 278\n",
      "truncating 254 - length: 300\n",
      "truncating 279 - length: 286\n",
      "truncating 301 - length: 284\n",
      "truncating 305 - length: 264\n",
      "truncating 312 - length: 262\n",
      "truncating 316 - length: 261\n",
      "truncating 358 - length: 282\n",
      "truncating 370 - length: 262\n",
      "truncating 371 - length: 257\n",
      "truncating 394 - length: 251\n",
      "truncating 399 - length: 263\n",
      "truncating 405 - length: 286\n",
      "truncating 409 - length: 281\n",
      "truncating 425 - length: 286\n",
      "truncating 440 - length: 265\n",
      "truncating 452 - length: 271\n",
      "truncating 471 - length: 284\n",
      "truncating 487 - length: 262\n",
      "truncating 516 - length: 265\n",
      "truncating 517 - length: 263\n",
      "truncating 518 - length: 298\n",
      "truncating 525 - length: 283\n",
      "truncating 549 - length: 281\n",
      "truncating 565 - length: 273\n",
      "truncating 571 - length: 254\n",
      "truncating 591 - length: 276\n",
      "truncating 650 - length: 277\n",
      "truncating 652 - length: 258\n",
      "truncating 656 - length: 257\n",
      "truncating 699 - length: 272\n",
      "truncating 701 - length: 295\n",
      "truncating 705 - length: 291\n",
      "truncating 719 - length: 272\n",
      "truncating 730 - length: 251\n",
      "truncating 737 - length: 251\n",
      "truncating 757 - length: 258\n",
      "truncating 777 - length: 271\n",
      "truncating 784 - length: 271\n",
      "truncating 788 - length: 281\n",
      "truncating 801 - length: 253\n",
      "truncating 832 - length: 298\n",
      "truncating 833 - length: 251\n",
      "truncating 843 - length: 262\n",
      "truncating 894 - length: 270\n",
      "truncating 903 - length: 274\n",
      "truncating 909 - length: 259\n",
      "truncating 921 - length: 290\n",
      "truncating 929 - length: 257\n",
      "truncating 955 - length: 281\n",
      "truncating 961 - length: 254\n",
      "truncating 969 - length: 272\n",
      "truncating 973 - length: 256\n",
      "truncating 975 - length: 269\n",
      "truncating 981 - length: 259\n",
      "truncating 995 - length: 273\n",
      "truncating 1043 - length: 254\n",
      "truncating 1047 - length: 294\n",
      "truncating 1063 - length: 271\n",
      "truncating 1099 - length: 295\n",
      "truncating 1118 - length: 297\n",
      "truncating 1140 - length: 264\n",
      "truncating 1173 - length: 280\n",
      "truncating 1253 - length: 281\n",
      "truncating 1259 - length: 293\n",
      "truncating 1329 - length: 297\n",
      "truncating 1335 - length: 253\n",
      "truncating 1343 - length: 251\n",
      "truncating 1353 - length: 265\n",
      "truncating 1359 - length: 264\n",
      "truncating 1365 - length: 254\n",
      "truncating 1393 - length: 289\n",
      "truncating 1399 - length: 267\n",
      "truncating 1400 - length: 267\n",
      "truncating 1408 - length: 280\n",
      "truncating 1448 - length: 300\n",
      "truncating 1482 - length: 253\n",
      "truncating 1501 - length: 264\n",
      "truncating 1518 - length: 284\n",
      "truncating 1527 - length: 299\n",
      "truncating 1590 - length: 280\n",
      "truncating 1630 - length: 257\n",
      "truncating 1631 - length: 277\n",
      "truncating 1639 - length: 291\n",
      "truncating 1644 - length: 261\n",
      "truncating 1660 - length: 299\n",
      "truncating 1669 - length: 272\n",
      "truncating 1676 - length: 265\n",
      "truncating 1699 - length: 268\n",
      "truncating 1704 - length: 276\n",
      "truncating 1705 - length: 264\n",
      "truncating 1714 - length: 292\n",
      "truncating 1758 - length: 283\n",
      "truncating 1790 - length: 297\n",
      "finished filtering - len(dataset) = 1800, len(data) = 1800\n",
      "truncating 5 - length: 262\n",
      "truncating 7 - length: 299\n",
      "truncating 22 - length: 296\n",
      "truncating 42 - length: 296\n",
      "truncating 44 - length: 266\n",
      "truncating 81 - length: 275\n",
      "truncating 132 - length: 252\n",
      "truncating 144 - length: 282\n",
      "truncating 164 - length: 289\n",
      "truncating 186 - length: 281\n",
      "truncating 227 - length: 277\n",
      "truncating 239 - length: 269\n",
      "truncating 257 - length: 266\n",
      "truncating 261 - length: 289\n",
      "truncating 276 - length: 284\n",
      "truncating 287 - length: 252\n",
      "truncating 295 - length: 252\n",
      "truncating 315 - length: 274\n",
      "truncating 344 - length: 298\n",
      "truncating 348 - length: 295\n",
      "truncating 367 - length: 258\n",
      "truncating 398 - length: 297\n",
      "truncating 408 - length: 285\n",
      "truncating 443 - length: 262\n",
      "truncating 457 - length: 258\n",
      "finished filtering - len(dataset) = 460, len(data) = 460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='22' class='' max='50000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.04% [22/50000 1:04:51&lt;2455:45:42]\n",
       "    </div>\n",
       "    \n",
       "Finished epoch 0. Validation Loss: 1.0141968856687131 (new best)<p>Finished epoch 1. Validation Loss: 0.6774514136107072 (new best)<p>Finished epoch 2. Validation Loss: 0.6063821808151577 (new best)<p>Finished epoch 3. Validation Loss: 0.5887661291205365 (new best)<p>Finished epoch 4. Validation Loss: 0.5779252492863199 (new best)<p>Finished epoch 5. Validation Loss: 0.5664786877839462 (new best)<p>Finished epoch 6. Validation Loss: 0.5518262619557588 (new best)<p>Finished epoch 7. Validation Loss: 0.5319478084211764 (new best)<p>Finished epoch 8. Validation Loss: 0.5126582695090253 (new best)<p>Finished epoch 9. Validation Loss: 0.5013107592644899 (new best)<p>Finished epoch 10. Validation Loss: 0.49037132962890295 (new best)<p>Finished epoch 11. Validation Loss: 0.484994658957357 (new best)<p>Finished epoch 12. Validation Loss: 0.4821012318134308 (new best)<p>Finished epoch 13. Validation Loss: 0.4791247430055038 (new best)<p>Finished epoch 14. Validation Loss: 0.47704955546752265 (new best)<p>Finished epoch 15. Validation Loss: 0.47369980552922125 (new best)<p>Finished epoch 16. Validation Loss: 0.4717209170693937 (new best)<p>Finished epoch 17. Validation Loss: 0.4698308732198632 (new best)<p>Finished epoch 18. Validation Loss: 0.4648881127005038 (new best)<p>Finished epoch 19. Validation Loss: 0.4598559478054876 (new best)<p>Finished epoch 20. Validation Loss: 0.456795615994412 (new best)<p>Finished epoch 21. Validation Loss: 0.452126813971478 (new best)<p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='5' class='' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      27.78% [5/18 00:51&lt;02:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "saving to: models/0381545/runid-0381545.pth\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/5c/cbscmcds4f93w9cj_gtp2m1h0000gn/T/ipykernel_79309/802877708.py\", line 11, in <module>\n",
      "    trainer.train()\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/trainer.py\", line 253, in train\n",
      "    val_avg_loss = self.validate_one_epoch(epoch)\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/trainer.py\", line 242, in train_one_epoch\n",
      "    loss=loss,\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/trainer.py\", line 202, in step\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/model.py\", line 150, in forward\n",
      "    embedding=lowerdim_output,\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/model.py\", line 138, in decode\n",
      "    x=target,\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/model.py\", line 66, in forward\n",
      "    x, block1, block2 = layer(x, enc_output, padding_mask, dec_target_padding_mask, look_ahead_mask)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/al/code/_svg/singleline_models/singleline_models/sketch_transformer/layers.py\", line 80, in forward\n",
      "    attn2, attn2_weights = self.mha2(x2, x2, out1, dec_target_padding_mask)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/modules/activation.py\", line 1189, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/functional.py\", line 5302, in multi_head_attention_forward\n",
      "    attn_output_weights = dropout(attn_output_weights, p=dropout_p)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/torch/nn/functional.py\", line 1252, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/al/miniconda3_m1/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from singleline_models.sketch_transformer.trainer import get_default_config, Trainer\n",
    "\n",
    "hp = get_default_config()\n",
    "hp.learning_rate = 1e-3\n",
    "hp.dataset_fname = 'data/look/epoch-20231214-filtered-trainval.npz'\n",
    "trainer = Trainer(hp=hp, use_wandb=False,\n",
    "                  device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# trainer.validate_one_epoch(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
