# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/lstm/00_shim.ipynb.

# %% auto 0
__all__ = ['lstm_layer']

# %% ../../nbs/lstm/00_shim.ipynb 2
from .rnnlib import *
from .custom_lstm import *

# %% ../../nbs/lstm/00_shim.ipynb 3
def lstm_layer(ni,
               nh,
               bidirectional=False,
               use_recurrent_dropout=False,
               r_dropout_prob=0.0,
               use_layer_norm=False,
               layer_norm_learnable=False,
               lstm_impl="builtin"):
    """
    Creates an LSTM layer, using a different underlying LSTM implementation.
    - 'builtin' uses pytorch `nn.LSTM`
    - 'rnnlib' uses LayerNormLSTM from `rnnlib`
    """
    if lstm_impl == 'builtin':
        assert not use_recurrent_dropout
        assert not use_layer_norm
        assert not layer_norm_learnable
        return nn.LSTM(ni, nh, bidirectional=bidirectional)
    elif lstm_impl == 'rnnlib':
        r_dropout = r_dropout_prob if use_recurrent_dropout else 0
        if use_layer_norm:
            return LayerNormLSTM(ni, nh, num_layers=1, bidirectional=bidirectional, layer_norm_enabled=True, r_dropout=r_dropout)
        rnn_cells = [[LSTMCell(ni, nh), LSTMCell(ni, nh)]] if bidirectional else [LSTMCell(ni, nh)]
        return LSTMFrame(rnn_cells, bidirectional=bidirectional, batch_first=False)
    else:
        raise NotImplementedError()

