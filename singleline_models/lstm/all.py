# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/lstm/index.ipynb.

# %% auto 0
__all__ = ['LSTM_BUILTIN', 'LSTM_RNNLIB', 'lstm_layer']

# %% ../../nbs/lstm/index.ipynb 2
from torch import nn

from .rnnlib import *
from .custom_lstm import *

# %% ../../nbs/lstm/index.ipynb 3
LSTM_BUILTIN = "builtin"
LSTM_RNNLIB = "rnnlib"

# %% ../../nbs/lstm/index.ipynb 4
def lstm_layer(ni,
               nh,
               bidirectional=False,
               use_recurrent_dropout=False,
               r_dropout_prob=0.0,
               use_layer_norm=False,
               layer_norm_learnable=False,
               lstm_impl=LSTM_BUILTIN):
    """
    Creates an LSTM layer, using a different underlying LSTM implementation.
    - 'builtin' uses pytorch `nn.LSTM`
    - 'rnnlib' uses LayerNormLSTM from `rnnlib`
    """
    if lstm_impl == LSTM_BUILTIN:
        assert not use_recurrent_dropout
        assert not use_layer_norm
        assert not layer_norm_learnable
        return nn.LSTM(ni, nh, bidirectional=bidirectional)
    elif lstm_impl == LSTM_RNNLIB:
        r_dropout = r_dropout_prob if use_recurrent_dropout else 0
        if use_layer_norm:
            return LayerNormLSTM(ni, nh, num_layers=1, bidirectional=bidirectional, layer_norm_enabled=True, r_dropout=r_dropout)
        rnn_cells = [[LSTMCell(ni, nh), LSTMCell(ni, nh)]] if bidirectional else [LSTMCell(ni, nh)]
        return LSTMFrame(rnn_cells, bidirectional=bidirectional, batch_first=False)
    else:
        raise NotImplementedError()

